#!/usr/bin/env python3
"""
AI Use Caseè‡ªå‹•ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
GitHubãƒªãƒ³ã‚¯ã‹ã‚‰ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹MDãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹
"""

import os
import sys
import subprocess
import json
import re
import time
import tempfile
import shutil
from datetime import datetime
from urllib.parse import urlparse
import argparse
import base64
import getpass

# æš—å·åŒ–æ©Ÿèƒ½ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«ï¼‰
try:
    from cryptography.fernet import Fernet
    from cryptography.hazmat.primitives import hashes
    from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC
    HAS_CRYPTOGRAPHY = True
except ImportError:
    HAS_CRYPTOGRAPHY = False

# requestsã®ä»£æ›¿ã¨ã—ã¦æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨
try:
    import requests
    HAS_REQUESTS = True
except ImportError:
    import urllib.request
    import urllib.error
    HAS_REQUESTS = False

class APIKeyManager:
    """APIã‚­ãƒ¼ã®æš—å·åŒ–ä¿å­˜ãƒ»å¾©å·åŒ–ã‚’ç®¡ç†"""
    
    def __init__(self, config_dir):
        self.config_dir = config_dir
        self.key_file = os.path.join(config_dir, ".api_keys.enc")
        os.makedirs(config_dir, exist_ok=True)
        
    def _derive_key(self, password: str, salt: bytes) -> bytes:
        """ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰æš—å·åŒ–ã‚­ãƒ¼ã‚’å°å‡º"""
        kdf = PBKDF2HMAC(
            algorithm=hashes.SHA256(),
            length=32,
            salt=salt,
            iterations=100000,
        )
        return base64.urlsafe_b64encode(kdf.derive(password.encode()))
    
    def save_api_key(self, service: str, api_key: str, password: str):
        """APIã‚­ãƒ¼ã‚’æš—å·åŒ–ã—ã¦ä¿å­˜"""
        if not HAS_CRYPTOGRAPHY:
            print("âš ï¸ æš—å·åŒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚'pip install cryptography' ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„")
            return False
        
        try:
            # æ—¢å­˜ã®ã‚­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ã‹ã€æ–°è¦ä½œæˆ
            data = {}
            salt = os.urandom(16)
            
            if os.path.exists(self.key_file):
                # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å¡©ã‚’èª­ã¿è¾¼ã¿
                with open(self.key_file, 'rb') as f:
                    salt = f.read(16)
                    encrypted_data = f.read()
                
                # å¾©å·åŒ–ã—ã¦æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                key = self._derive_key(password, salt)
                fernet = Fernet(key)
                decrypted_data = fernet.decrypt(encrypted_data)
                data = json.loads(decrypted_data.decode())
            
            # æ–°ã—ã„APIã‚­ãƒ¼ã‚’è¿½åŠ 
            data[service] = api_key
            
            # æš—å·åŒ–ã—ã¦ä¿å­˜
            key = self._derive_key(password, salt)
            fernet = Fernet(key)
            encrypted_data = fernet.encrypt(json.dumps(data).encode())
            
            with open(self.key_file, 'wb') as f:
                f.write(salt)
                f.write(encrypted_data)
            
            print(f"âœ… {service} APIã‚­ãƒ¼ã‚’æš—å·åŒ–ä¿å­˜ã—ã¾ã—ãŸ")
            return True
            
        except Exception as e:
            print(f"âŒ APIã‚­ãƒ¼ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def load_api_key(self, service: str, password: str) -> str:
        """æš—å·åŒ–ã•ã‚ŒãŸAPIã‚­ãƒ¼ã‚’å¾©å·åŒ–ã—ã¦å–å¾—"""
        if not HAS_CRYPTOGRAPHY:
            return None
        
        try:
            if not os.path.exists(self.key_file):
                return None
            
            with open(self.key_file, 'rb') as f:
                salt = f.read(16)
                encrypted_data = f.read()
            
            key = self._derive_key(password, salt)
            fernet = Fernet(key)
            decrypted_data = fernet.decrypt(encrypted_data)
            data = json.loads(decrypted_data.decode())
            
            return data.get(service)
            
        except Exception:
            return None
    
    def has_stored_keys(self) -> bool:
        """ä¿å­˜ã•ã‚ŒãŸAPIã‚­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª"""
        return os.path.exists(self.key_file)

class ProgressBar:
    """ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼è¡¨ç¤º"""
    def __init__(self, width=40):
        self.width = width
        self.current = 0
        
    def show(self, message="å‡¦ç†ä¸­"):
        """ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ä»˜ããƒ—ãƒ­ã‚°ãƒ¬ã‚¹è¡¨ç¤º"""
        chars = "â ‹â ™â ¹â ¸â ¼â ´â ¦â §â ‡â "
        char = chars[self.current % len(chars)]
        self.current += 1
        print(f"\r{char} {message}...", end="", flush=True)
        time.sleep(0.1)
    
    def finish(self, message="å®Œäº†"):
        """ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹å®Œäº†"""
        print(f"\râœ… {message}")

def extract_clean_output(raw_output):
    """AIã®å‡ºåŠ›ã‹ã‚‰ä¸»è¦ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ï¼ˆJSONã‚„Markdownï¼‰ã‚’æŠ½å‡ºãƒ»æ•´å½¢ã™ã‚‹"""
    
    # 1. YAMLãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ä»˜ãã®Markdownå…¨ä½“ã‚’æ¤œç´¢ï¼ˆæœ€å„ªå…ˆï¼‰
    md_search = re.search(r"^---\s*\n.*?\n---\s*\n.*", raw_output, re.DOTALL)
    if md_search:
        return md_search.group(0)

    # 2. ```markdown ... ``` ãƒ–ãƒ­ãƒƒã‚¯ã‚’æ¤œç´¢
    md_block_search = re.search(r"```markdown\s*(.*?)\s*```", raw_output, re.DOTALL)
    if md_block_search:
        return md_block_search.group(1)

    # 3. ```json ... ``` ãƒ–ãƒ­ãƒƒã‚¯ã‚’æ¤œç´¢
    json_search = re.search(r"```(json)?\s*(\{.*?\})\s*```", raw_output, re.DOTALL)
    if json_search:
        try:
            json.loads(json_search.group(2))
            return json_search.group(2)
        except json.JSONDecodeError:
            pass

    # 4. JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ç›´æ¥æ¤œç´¢ï¼ˆã‚ˆã‚ŠåŒ…æ‹¬çš„ãªæ¤œç´¢ï¼‰
    # è¤‡æ•°è¡Œã«ã‚ãŸã‚‹JSONã‚’å‡¦ç†
    lines = raw_output.split('\n')
    json_lines = []
    in_json = False
    brace_count = 0
    
    for line in lines:
        # JSONã®é–‹å§‹ã‚’æ¤œå‡º
        if '{' in line and not in_json:
            in_json = True
            brace_count = line.count('{') - line.count('}')
            json_lines.append(line)
        elif in_json:
            brace_count += line.count('{') - line.count('}')
            json_lines.append(line)
            # JSONã®çµ‚äº†ã‚’æ¤œå‡º
            if brace_count <= 0:
                break
    
    if json_lines:
        potential_json = '\n'.join(json_lines)
        # æœ€åˆã®{ã‹ã‚‰æœ€å¾Œã®}ã¾ã§ã‚’æŠ½å‡º
        start_idx = potential_json.find('{')
        end_idx = potential_json.rfind('}') + 1
        if start_idx != -1 and end_idx > start_idx:
            potential_json = potential_json[start_idx:end_idx]
            try:
                json.loads(potential_json)
                return potential_json
            except json.JSONDecodeError:
                pass

    # 5. å˜ç´”ãªJSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ¤œç´¢ï¼ˆå…ƒã®æ–¹æ³•ï¼‰
    json_start = raw_output.find('{')
    json_end = raw_output.rfind('}') + 1
    if json_start != -1 and json_end > json_start:
        potential_json = raw_output[json_start:json_end]
        try:
            json.loads(potential_json)
            return potential_json
        except json.JSONDecodeError:
            pass

    # 6. ä½•ã‚‚è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€å‰å¾Œã®ç©ºç™½ã‚’é™¤å»ã—ã¦ãã®ã¾ã¾è¿”ã™
    return raw_output.strip()


class MultiStageAnalyzer:
    """é«˜ç²¾åº¦å¤šæ®µéšåˆ†æã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆGemini/Claudeå¯¾å¿œï¼‰"""
    
    def __init__(self, github_url, repo_name, temp_dir, cli_outputs_dir, ai_provider="gemini", openai_api_key=None):
        self.github_url = github_url
        self.repo_name = repo_name
        self.temp_dir = temp_dir
        self.cli_outputs_dir = cli_outputs_dir
        self.ai_provider = ai_provider
        self.openai_api_key = openai_api_key
        self.analysis_data = {}
        self.project_root = os.path.dirname(cli_outputs_dir)
        
    def save_stage_data(self, stage, data):
        """æ®µéšåˆ¥ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ™‚ä¿å­˜"""
        stage_file = os.path.join(self.temp_dir, f"stage_{stage}.json")
        with open(stage_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    
    def load_stage_data(self, stage):
        """æ®µéšåˆ¥ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        stage_file = os.path.join(self.temp_dir, f"stage_{stage}.json")
        if os.path.exists(stage_file):
            with open(stage_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return None
    
    def execute_ai_analysis(self, prompt, stage_name):
        """AI CLIã‚’å®Ÿè¡Œã—ã¦åˆ†æï¼ˆGemini/Claudeï¼‰"""
        try:
            print(f"\nğŸ” {stage_name} - {self.ai_provider.upper()}åˆ†æå®Ÿè¡Œä¸­...")
            
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
            progress = ProgressBar()
            import threading
            stop_progress = threading.Event()
            
            def show_progress():
                while not stop_progress.is_set():
                    progress.show(f"{stage_name}")
            
            progress_thread = threading.Thread(target=show_progress)
            progress_thread.daemon = True
            progress_thread.start()
            
            # AI CLIå®Ÿè¡Œ
            if self.ai_provider == "gemini":
                cmd = ["gemini", "chat", "--prompt", prompt]
                timeout = 300  # 5åˆ†
                result = subprocess.run(
                    cmd, 
                    capture_output=True, 
                    text=True, 
                    timeout=timeout
                )
            elif self.ai_provider == "claude":
                cmd = ["claude", prompt]
                timeout = 300  # 5åˆ†
                result = subprocess.run(
                    cmd, 
                    capture_output=True, 
                    text=True, 
                    timeout=timeout
                )
            elif self.ai_provider == "chatgpt":
                # ChatGPT APIå‘¼ã³å‡ºã—
                result = self._call_chatgpt_api(prompt)
                timeout = 300  # 5åˆ†
            else:
                raise ValueError(f"Unsupported AI provider: {self.ai_provider}")
            
            stop_progress.set()
            progress_thread.join(timeout=0.5)
            
            # CLIã®ç”Ÿå‡ºåŠ›ã‚’ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            safe_stage_name = re.sub(r'[^\w\-_]', '_', stage_name)
            raw_output_filename = f"{timestamp}_{self.repo_name}_{safe_stage_name}.log"
            raw_output_path = os.path.join(self.cli_outputs_dir, raw_output_filename)
            
            log_content = f"""# AI Analysis Log

- **Repository**: {self.github_url}
- **AI Provider**: {self.ai_provider}
- **Stage**: {stage_name}
- **Timestamp**: {timestamp}

## Prompt

```
{prompt}
```

## Raw STDOUT

```
{result.stdout}
```

## Raw STDERR

```
{result.stderr}
```
"""
            with open(raw_output_path, 'w', encoding='utf-8') as f:
                f.write(log_content)

            if result.returncode == 0:
                progress.finish(f"{stage_name} å®Œäº†")
                # æ•´å½¢ã•ã‚ŒãŸå‡ºåŠ›ã‚’è¿”ã™
                return extract_clean_output(result.stdout)
            else:
                progress.finish(f"{stage_name} å¤±æ•—")
                # ã‚¯ã‚©ãƒ¼ã‚¿ã‚¨ãƒ©ãƒ¼ã‹ã©ã†ã‹ãƒã‚§ãƒƒã‚¯
                if "Quota exceeded" in result.stderr or "429" in result.stderr:
                    print(f"âš ï¸ {self.ai_provider.upper()} APIã‚¯ã‚©ãƒ¼ã‚¿åˆ¶é™ã«é”ã—ã¾ã—ãŸ")
                    print(f"ğŸ’¡ åˆ¥ã®AIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’è©¦ã™ã‹ã€æ™‚é–“ã‚’ãŠã„ã¦å†å®Ÿè¡Œã—ã¦ãã ã•ã„")
                else:
                    print(f"âŒ ã‚¨ãƒ©ãƒ¼: {result.stderr}")
                return None
                
        except subprocess.TimeoutExpired:
            stop_progress.set()
            progress.finish(f"{stage_name} ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
            print(f"â° {self.ai_provider.upper()} {stage_name} ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ")
            return None
        except Exception as e:
            stop_progress.set()
            progress.finish(f"{stage_name} ã‚¨ãƒ©ãƒ¼")
            print(f"âŒ {self.ai_provider.upper()} {stage_name} ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return None
    
    def _call_chatgpt_api(self, prompt):
        """ChatGPT APIã‚’å‘¼ã³å‡ºã™"""
        try:
            if not self.openai_api_key:
                raise ValueError("OpenAI API key is required for ChatGPT")
            
            if not HAS_REQUESTS:
                raise ValueError("requests library is required for ChatGPT API")
            
            headers = {
                "Authorization": f"Bearer {self.openai_api_key}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": "gpt-4o",
                "messages": [
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "max_tokens": 4000,
                "temperature": 0.7
            }
            
            response = requests.post(
                "https://api.openai.com/v1/chat/completions",
                headers=headers,
                json=data,
                timeout=300
            )
            
            if response.status_code == 200:
                result_data = response.json()
                content = result_data['choices'][0]['message']['content']
                
                # subprocess.runçµæœã¨åŒã˜å½¢å¼ã«ãƒ©ãƒƒãƒ—
                class MockResult:
                    def __init__(self, stdout, stderr="", returncode=0):
                        self.stdout = stdout
                        self.stderr = stderr
                        self.returncode = returncode
                
                return MockResult(content)
            else:
                error_msg = f"ChatGPT API error: {response.status_code} - {response.text}"
                return MockResult("", error_msg, 1)
                
        except Exception as e:
            return MockResult("", str(e), 1)
    
    def stage_1_basic_analysis(self):
        """Stage 1: åŸºæœ¬æƒ…å ±åé›†"""
        prompt = f"""
GitHubãƒªãƒã‚¸ãƒˆãƒª {self.github_url} ã‚’åˆ†æã—ã¦ã€ä»¥ä¸‹ã®JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚

é‡è¦ï¼šå¿…ãšJSONã®ã¿ã§å›ç­”ã—ã€èª¬æ˜ã‚„è¿½åŠ ãƒ†ã‚­ã‚¹ãƒˆã¯å«ã‚ãªã„ã§ãã ã•ã„ã€‚

{{
  "repository_name": "ãƒªãƒã‚¸ãƒˆãƒªå",
  "description": "ãƒªãƒã‚¸ãƒˆãƒªã®èª¬æ˜",
  "main_purpose": "ä¸»ãªç›®çš„",
  "tech_stack": {{
    "languages": ["è¨€èª1", "è¨€èª2"],
    "frameworks": ["ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯1", "ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯2"],
    "libraries": ["ãƒ©ã‚¤ãƒ–ãƒ©ãƒª1", "ãƒ©ã‚¤ãƒ–ãƒ©ãƒª2"]
  }},
  "file_structure": {{
    "key_directories": ["ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª1", "ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª2"],
    "important_files": ["ãƒ•ã‚¡ã‚¤ãƒ«1", "ãƒ•ã‚¡ã‚¤ãƒ«2"]
  }},
  "documentation": {{
    "has_readme": true,
    "readme_quality": "è‰¯å¥½",
    "other_docs": ["ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ1", "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ2"]
  }},
  "contributors": ["ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚¿ãƒ¼1", "ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚¿ãƒ¼2"],
  "license": "ãƒ©ã‚¤ã‚»ãƒ³ã‚¹å"
}}
        """
        
        result = self.execute_ai_analysis(prompt, "Stage 1: åŸºæœ¬æƒ…å ±åé›†")
        if result:
            try:
                # JSONãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
                json_data = json.loads(result)
                self.save_stage_data("1_basic", json_data)
                return json_data
            except json.JSONDecodeError:
                print("âš ï¸ Stage 1 JSONè§£æã‚¨ãƒ©ãƒ¼ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ")
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
                fallback_data = {
                    "repository_name": self.repo_name,
                    "description": "GitHub repository analysis",
                    "main_purpose": "Code repository",
                    "tech_stack": {
                        "languages": ["Unknown"],
                        "frameworks": ["Unknown"],
                        "libraries": ["Unknown"]
                    },
                    "file_structure": {
                        "key_directories": ["Unknown"],
                        "important_files": ["Unknown"]
                    },
                    "documentation": {
                        "has_readme": True,
                        "readme_quality": "Unknown",
                        "other_docs": ["Unknown"]
                    },
                    "contributors": ["Unknown"],
                    "license": "Unknown"
                }
                self.save_stage_data("1_basic", fallback_data)
                self.save_stage_data("1_basic_raw", {"raw_output": result})
                print("âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦Stage 2ã«ç¶™ç¶š")
                return fallback_data
        return None
    
    def stage_2_deep_code_analysis(self):
        """Stage 2: è©³ç´°ã‚³ãƒ¼ãƒ‰åˆ†æ"""
        stage1_data = self.load_stage_data("1_basic")
        
        if not stage1_data:
            print("âš ï¸ Stage 1ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚Stage 2ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            return None
        
        prompt = f"""
ãƒªãƒã‚¸ãƒˆãƒª {self.github_url} ã®ã‚³ãƒ¼ãƒ‰ã‚’è©³ç´°ã«åˆ†æã—ã¦ãã ã•ã„ã€‚

## Stage 1ã§å¾—ã‚‰ã‚ŒãŸåŸºæœ¬æƒ…å ±ï¼š
{json.dumps(stage1_data, ensure_ascii=False, indent=2)}

## è©³ç´°åˆ†æé …ç›®ï¼š
1. ã‚³ãƒ¼ãƒ‰ã®å“è³ªãƒ»æ§‹é€ åˆ†æ
2. ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç‰¹å®š
3. è¨­è¨ˆåŸå‰‡ã®é©ç”¨çŠ¶æ³
4. ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ã¨å“è³ª
5. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¸Šã®è€ƒæ…®äº‹é …
6. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç‰¹æ€§
7. æ‹¡å¼µæ€§ãƒ»ä¿å®ˆæ€§ã®è©•ä¾¡

## å›ç­”å½¢å¼ï¼š
ä»¥ä¸‹ã®JSONå½¢å¼ã§å³å¯†ã«å›ç­”ã—ã¦ãã ã•ã„ï¼š

```json
{{
  "code_quality": {{
    "overall_rating": "å„ªç§€/è‰¯å¥½/æ™®é€š/æ”¹å–„å¿…è¦",
    "code_style": "ä¸€è²«æ€§ã®è©•ä¾¡",
    "documentation": "ã‚³ãƒ¡ãƒ³ãƒˆãƒ»ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®è©•ä¾¡"
  }},
  "architecture": {{
    "pattern": "ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ‘ã‚¿ãƒ¼ãƒ³å",
    "design_principles": ["åŸå‰‡1", "åŸå‰‡2"],
    "modularity": "ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ€§ã®è©•ä¾¡"
  }},
  "testing": {{
    "has_tests": true/false,
    "test_coverage": "ã‚«ãƒãƒ¬ãƒƒã‚¸æ¨å®š",
    "test_quality": "ãƒ†ã‚¹ãƒˆå“è³ªè©•ä¾¡"
  }},
  "security": {{
    "security_practices": ["å®Ÿè·µ1", "å®Ÿè·µ2"],
    "potential_risks": ["ãƒªã‚¹ã‚¯1", "ãƒªã‚¹ã‚¯2"]
  }},
  "performance": {{
    "optimization_level": "æœ€é©åŒ–ãƒ¬ãƒ™ãƒ«",
    "bottlenecks": ["ãƒœãƒˆãƒ«ãƒãƒƒã‚¯1", "ãƒœãƒˆãƒ«ãƒãƒƒã‚¯2"]
  }},
  "maintainability": {{
    "code_complexity": "è¤‡é›‘åº¦è©•ä¾¡",
    "extensibility": "æ‹¡å¼µæ€§è©•ä¾¡",
    "refactoring_needs": ["æ”¹å–„ç‚¹1", "æ”¹å–„ç‚¹2"]
  }}
}}
```

è©³ç´°ãªã‚³ãƒ¼ãƒ‰åˆ†æã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚
        """
        
        result = self.execute_ai_analysis(prompt, "Stage 2: è©³ç´°ã‚³ãƒ¼ãƒ‰åˆ†æ")
        if result:
            try:
                json_data = json.loads(result)
                self.save_stage_data("2_deep_analysis", json_data)
                return json_data
            except json.JSONDecodeError:
                print("âš ï¸ Stage 2 JSONè§£æã‚¨ãƒ©ãƒ¼ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ")
                fallback_data = {
                    "code_quality": {
                        "overall_rating": "æ™®é€š",
                        "code_style": "Unknown",
                        "documentation": "Unknown"
                    },
                    "architecture": {
                        "pattern": "Unknown",
                        "design_principles": ["Unknown"],
                        "modularity": "Unknown"
                    },
                    "testing": {
                        "has_tests": False,
                        "test_coverage": "Unknown",
                        "test_quality": "Unknown"
                    },
                    "security": {
                        "security_practices": ["Unknown"],
                        "potential_risks": ["Unknown"]
                    },
                    "performance": {
                        "optimization_level": "Unknown",
                        "bottlenecks": ["Unknown"]
                    },
                    "maintainability": {
                        "code_complexity": "Unknown",
                        "extensibility": "Unknown",
                        "refactoring_needs": ["Unknown"]
                    }
                }
                self.save_stage_data("2_deep_analysis", fallback_data)
                self.save_stage_data("2_deep_analysis_raw", {"raw_output": result})
                print("âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦Stage 3ã«ç¶™ç¶š")
                return fallback_data
        return None
    
    def stage_3_consistency_check(self):
        """Stage 3: æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ã¨è£œå®Œ"""
        stage1_data = self.load_stage_data("1_basic")
        stage2_data = self.load_stage_data("2_deep_analysis")
        
        if not stage1_data or not stage2_data:
            print("âš ï¸ å‰æ®µéšã®ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚Stage 3ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            return None
        
        prompt = f"""
ã“ã‚Œã¾ã§ã®åˆ†æçµæœã®æ•´åˆæ€§ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€ä¸è¶³æƒ…å ±ã‚’è£œå®Œã—ã¦ãã ã•ã„ã€‚

## Stage 1 åŸºæœ¬æƒ…å ±ï¼š
{json.dumps(stage1_data, ensure_ascii=False, indent=2)}

## Stage 2 è©³ç´°åˆ†æï¼š
{json.dumps(stage2_data, ensure_ascii=False, indent=2)}

## ãƒã‚§ãƒƒã‚¯ãƒ»è£œå®Œé …ç›®ï¼š
1. æƒ…å ±ã®æ•´åˆæ€§ç¢ºèª
2. ä¸è¶³ã—ã¦ã„ã‚‹æŠ€è¡“çš„è©³ç´°ã®è£œå®Œ
3. AI/MLæŠ€è¡“ã®ä½¿ç”¨çŠ¶æ³ã®ç‰¹å®š
4. ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤ãƒ»å®Ÿç”¨æ€§ã®è©•ä¾¡
5. ç«¶åˆå„ªä½æ€§ã®åˆ†æ
6. æ”¹å–„ææ¡ˆã®å…·ä½“åŒ–

## å›ç­”å½¢å¼ï¼š
ä»¥ä¸‹ã®JSONå½¢å¼ã§å³å¯†ã«å›ç­”ã—ã¦ãã ã•ã„ï¼š

```json
{{
  "consistency_check": {{
    "data_consistency": "æ•´åˆæ€§è©•ä¾¡",
    "contradictions": ["çŸ›ç›¾ç‚¹1", "çŸ›ç›¾ç‚¹2"],
    "missing_info": ["ä¸è¶³æƒ…å ±1", "ä¸è¶³æƒ…å ±2"]
  }},
  "ai_ml_usage": {{
    "uses_ai_ml": true/false,
    "ai_technologies": ["æŠ€è¡“1", "æŠ€è¡“2"],
    "ml_frameworks": ["ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯1", "ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯2"],
    "ai_applications": ["ç”¨é€”1", "ç”¨é€”2"]
  }},
  "business_value": {{
    "target_users": ["ãƒ¦ãƒ¼ã‚¶ãƒ¼1", "ãƒ¦ãƒ¼ã‚¶ãƒ¼2"],
    "business_problems": ["èª²é¡Œ1", "èª²é¡Œ2"],
    "value_proposition": "ä¾¡å€¤ææ¡ˆ",
    "market_potential": "å¸‚å ´ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«"
  }},
  "competitive_advantage": {{
    "unique_features": ["ç‰¹å¾´1", "ç‰¹å¾´2"],
    "differentiation": "å·®åˆ¥åŒ–è¦å› ",
    "innovation_level": "é©æ–°æ€§ãƒ¬ãƒ™ãƒ«"
  }},
  "improvement_suggestions": ["æ”¹å–„æ¡ˆ1", "æ”¹å–„æ¡ˆ2"]
}}
```

è©³ç´°ãªæ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ã¨è£œå®Œã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚
        """
        
        result = self.execute_ai_analysis(prompt, "Stage 3: æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯")
        if result:
            try:
                json_data = json.loads(result)
                self.save_stage_data("3_consistency", json_data)
                return json_data
            except json.JSONDecodeError:
                print("âš ï¸ Stage 3 JSONè§£æã‚¨ãƒ©ãƒ¼ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ")
                fallback_data = {
                    "consistency_check": {
                        "data_consistency": "æ™®é€š",
                        "contradictions": ["Unknown"],
                        "missing_info": ["Unknown"]
                    },
                    "ai_ml_usage": {
                        "uses_ai_ml": False,
                        "ai_technologies": ["Unknown"],
                        "ml_frameworks": ["Unknown"],
                        "ai_applications": ["Unknown"]
                    },
                    "business_value": {
                        "target_users": ["Unknown"],
                        "business_problems": ["Unknown"],
                        "value_proposition": "Unknown",
                        "market_potential": "Unknown"
                    },
                    "competitive_advantage": {
                        "unique_features": ["Unknown"],
                        "differentiation": "Unknown",
                        "innovation_level": "Unknown"
                    },
                    "improvement_suggestions": ["Unknown"]
                }
                self.save_stage_data("3_consistency", fallback_data)
                self.save_stage_data("3_consistency_raw", {"raw_output": result})
                print("âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦Stage 4ã«ç¶™ç¶š")
                return fallback_data
        return None
    
    def stage_4_deep_insights(self):
        """Stage 4: ãƒ‡ã‚£ãƒ¼ãƒ—åˆ†æãƒ»æ´å¯Ÿ"""
        stage1_data = self.load_stage_data("1_basic")
        stage2_data = self.load_stage_data("2_deep_analysis")
        stage3_data = self.load_stage_data("3_consistency")
        
        if not all([stage1_data, stage2_data, stage3_data]):
            print("âš ï¸ å‰æ®µéšã®ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚Stage 4ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            return None
        
        prompt = f"""
ã“ã‚Œã¾ã§ã®å…¨åˆ†æçµæœã‚’çµ±åˆã—ã€æ·±ã„æ´å¯Ÿã¨æˆ¦ç•¥çš„è¦–ç‚¹ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

## çµ±åˆãƒ‡ãƒ¼ã‚¿ï¼š
### Stage 1 åŸºæœ¬æƒ…å ±ï¼š
{json.dumps(stage1_data, ensure_ascii=False, indent=2)}

### Stage 2 è©³ç´°åˆ†æï¼š
{json.dumps(stage2_data, ensure_ascii=False, indent=2)}

### Stage 3 æ•´åˆæ€§ãƒ»è£œå®Œï¼š
{json.dumps(stage3_data, ensure_ascii=False, indent=2)}

## æ·±ã„æ´å¯Ÿé …ç›®ï¼š
1. æŠ€è¡“çš„é©æ–°æ€§ã¨å°†æ¥æ€§
2. å®Ÿè£…ã®è¤‡é›‘ã•ã¨å®Ÿç¾å¯èƒ½æ€§
3. ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹äºˆæ¸¬
4. ãƒªã‚¹ã‚¯åˆ†æã¨å¯¾ç­–
5. æŠ•è³‡å¯¾åŠ¹æœã¨ ROI äºˆæ¸¬
6. ä»–åˆ†é‡ã¸ã®å¿œç”¨å¯èƒ½æ€§
7. æ¥­ç•Œãƒˆãƒ¬ãƒ³ãƒ‰ã¨ã®æ•´åˆæ€§

## å›ç­”å½¢å¼ï¼š
ä»¥ä¸‹ã®JSONå½¢å¼ã§å³å¯†ã«å›ç­”ã—ã¦ãã ã•ã„ï¼š

```json
{{
  "innovation_analysis": {{
    "innovation_level": "é©æ–°ãƒ¬ãƒ™ãƒ«ï¼ˆ1-10ï¼‰",
    "future_potential": "å°†æ¥æ€§è©•ä¾¡",
    "technology_maturity": "æŠ€è¡“æˆç†Ÿåº¦",
    "adoption_barriers": ["å°å…¥éšœå£1", "å°å…¥éšœå£2"]
  }},
  "implementation_complexity": {{
    "complexity_rating": "è¤‡é›‘åº¦ï¼ˆ1-10ï¼‰",
    "development_time": "é–‹ç™ºæœŸé–“äºˆæ¸¬",
    "required_expertise": ["å¿…è¦å°‚é–€çŸ¥è­˜1", "å¿…è¦å°‚é–€çŸ¥è­˜2"],
    "infrastructure_needs": ["ã‚¤ãƒ³ãƒ•ãƒ©è¦ä»¶1", "ã‚¤ãƒ³ãƒ•ãƒ©è¦ä»¶2"]
  }},
  "scalability_performance": {{
    "scalability_potential": "ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«",
    "performance_bottlenecks": ["ãƒœãƒˆãƒ«ãƒãƒƒã‚¯1", "ãƒœãƒˆãƒ«ãƒãƒƒã‚¯2"],
    "optimization_opportunities": ["æœ€é©åŒ–æ©Ÿä¼š1", "æœ€é©åŒ–æ©Ÿä¼š2"]
  }},
  "risk_analysis": {{
    "technical_risks": ["æŠ€è¡“ãƒªã‚¹ã‚¯1", "æŠ€è¡“ãƒªã‚¹ã‚¯2"],
    "business_risks": ["ãƒ“ã‚¸ãƒã‚¹ãƒªã‚¹ã‚¯1", "ãƒ“ã‚¸ãƒã‚¹ãƒªã‚¹ã‚¯2"],
    "mitigation_strategies": ["å¯¾ç­–1", "å¯¾ç­–2"]
  }},
  "roi_analysis": {{
    "investment_level": "æŠ•è³‡ãƒ¬ãƒ™ãƒ«",
    "expected_returns": "æœŸå¾…åç›Š",
    "payback_period": "æŠ•è³‡å›åæœŸé–“",
    "cost_benefit_ratio": "ã‚³ã‚¹ãƒˆãƒ™ãƒãƒ•ã‚£ãƒƒãƒˆæ¯”"
  }},
  "application_potential": {{
    "other_industries": ["é©ç”¨å¯èƒ½æ¥­ç•Œ1", "é©ç”¨å¯èƒ½æ¥­ç•Œ2"],
    "extension_possibilities": ["æ‹¡å¼µå¯èƒ½æ€§1", "æ‹¡å¼µå¯èƒ½æ€§2"],
    "ecosystem_impact": "ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã¸ã®å½±éŸ¿"
  }},
  "industry_alignment": {{
    "current_trends": ["ãƒˆãƒ¬ãƒ³ãƒ‰1", "ãƒˆãƒ¬ãƒ³ãƒ‰2"],
    "market_timing": "å¸‚å ´ã‚¿ã‚¤ãƒŸãƒ³ã‚°è©•ä¾¡",
    "competitive_landscape": "ç«¶åˆçŠ¶æ³"
  }}
}}
```

æ·±ã„æ´å¯Ÿã¨åˆ†æã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
        """
        
        result = self.execute_ai_analysis(prompt, "Stage 4: ãƒ‡ã‚£ãƒ¼ãƒ—åˆ†æ")
        if result:
            try:
                json_data = json.loads(result)
                self.save_stage_data("4_deep_insights", json_data)
                return json_data
            except json.JSONDecodeError:
                print("âš ï¸ Stage 4 JSONè§£æã‚¨ãƒ©ãƒ¼ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ")
                fallback_data = {
                    "innovation_analysis": {
                        "innovation_level": "5",
                        "future_potential": "æ™®é€š",
                        "technology_maturity": "æ™®é€š",
                        "adoption_barriers": ["Unknown"]
                    },
                    "implementation_complexity": {
                        "complexity_rating": "5",
                        "development_time": "Unknown",
                        "required_expertise": ["Unknown"],
                        "infrastructure_needs": ["Unknown"]
                    },
                    "scalability_performance": {
                        "scalability_potential": "æ™®é€š",
                        "performance_bottlenecks": ["Unknown"],
                        "optimization_opportunities": ["Unknown"]
                    },
                    "risk_analysis": {
                        "technical_risks": ["Unknown"],
                        "business_risks": ["Unknown"],
                        "mitigation_strategies": ["Unknown"]
                    },
                    "roi_analysis": {
                        "investment_level": "æ™®é€š",
                        "expected_returns": "Unknown",
                        "payback_period": "Unknown",
                        "cost_benefit_ratio": "Unknown"
                    },
                    "application_potential": {
                        "other_industries": ["Unknown"],
                        "extension_possibilities": ["Unknown"],
                        "ecosystem_impact": "Unknown"
                    },
                    "industry_alignment": {
                        "current_trends": ["Unknown"],
                        "market_timing": "æ™®é€š",
                        "competitive_landscape": "Unknown"
                    }
                }
                self.save_stage_data("4_deep_insights", fallback_data)
                self.save_stage_data("4_deep_insights_raw", {"raw_output": result})
                print("âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦Stage 5ã«ç¶™ç¶š")
                return fallback_data
        return None
    
    def stage_5_final_synthesis(self):
        """Stage 5: æœ€çµ‚çµ±åˆãƒ»MDãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆ"""
        # å…¨æ®µéšã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        stage1_data = self.load_stage_data("1_basic")
        stage2_data = self.load_stage_data("2_deep_analysis")
        stage3_data = self.load_stage_data("3_consistency")
        stage4_data = self.load_stage_data("4_deep_insights")
        
        # æ—¢å­˜ã®è‰¯ã„ã‚µãƒ³ãƒ—ãƒ«ã‚’å‚è€ƒä¾‹ã¨ã—ã¦èª­ã¿è¾¼ã¿
        sample_usecase = self._load_sample_usecase()
        template = self._load_template()
        
        prompt = f"""
ã‚ãªãŸã¯AIãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚GitHubãƒªãƒã‚¸ãƒˆãƒªã‚’åˆ†æã—ã¦ã€é«˜å“è³ªãªãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

## åˆ†æå¯¾è±¡
- **ãƒªãƒã‚¸ãƒˆãƒª**: {self.github_url}
- **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå**: {self.repo_name}

## åˆ©ç”¨å¯èƒ½ãªåˆ†æãƒ‡ãƒ¼ã‚¿
{self._format_analysis_data_for_prompt(stage1_data, stage2_data, stage3_data, stage4_data)}

## å‚è€ƒãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆè‰¯ã„ã‚µãƒ³ãƒ—ãƒ«ï¼‰
{sample_usecase}

## å¿…é ˆè¦æ±‚äº‹é …

1. **å³å¯†ãªYAMLãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼**ï¼ˆä»¥ä¸‹ã®å½¢å¼ã‚’å¿…ãšä½¿ç”¨ï¼‰ï¼š
```yaml
---
title: "[å…·ä½“çš„ã§åˆ†ã‹ã‚Šã‚„ã™ã„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¿ã‚¤ãƒˆãƒ«]"
summary: "[1-2æ–‡ã®ç°¡æ½”ã§çš„ç¢ºãªæ¦‚è¦]"
category: "[é©åˆ‡ãªã‚«ãƒ†ã‚´ãƒªï¼šAIãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹/Webé–‹ç™º/ãƒ‡ãƒ¼ã‚¿åˆ†æ/ãƒ¢ãƒã‚¤ãƒ«ã‚¢ãƒ—ãƒª/ãƒ„ãƒ¼ãƒ«/ãƒ©ã‚¤ãƒ–ãƒ©ãƒª/ãã®ä»–]"
industry: "[å¯¾è±¡æ¥­ç•Œï¼šITãƒ»ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢/è£½é€ æ¥­/é‡‘è/ãƒ˜ãƒ«ã‚¹ã‚±ã‚¢/æ•™è‚²/ã‚¨ãƒ³ã‚¿ãƒ¡/ãã®ä»–]"
createdAt: {datetime.now().strftime('%Y-%m-%d')}
updatedAt: {datetime.now().strftime('%Y-%m-%d')}
status: "[é–‹ç™ºä¸­/å®Œäº†/å®Ÿé¨“çš„/ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–/ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ä¸­]"
github_link: {self.github_url}
contributors:
  - "[å®Ÿéš›ã®ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚¿ãƒ¼å]"
tags:
  - "[ä¸»è¦æŠ€è¡“ã‚¿ã‚°1]"
  - "[ä¸»è¦æŠ€è¡“ã‚¿ã‚°2]"
  - "[ä¸»è¦æŠ€è¡“ã‚¿ã‚°3]"
---
```

2. **é«˜å“è³ªãªMarkdownæ§‹é€ **ï¼š
- ãƒªãƒã‚¸ãƒˆãƒªã®å®Ÿéš›ã®å†…å®¹ã«åŸºã¥ã„ãŸæ­£ç¢ºãªåˆ†æ
- æŠ€è¡“çš„è©³ç´°ã®å…·ä½“æ€§
- å®Ÿç”¨çš„ä¾¡å€¤ã®æ˜ç¢ºåŒ–
- èª­ã¿ã‚„ã™ãæ§‹é€ åŒ–ã•ã‚ŒãŸæ–‡ç« 

3. **å“è³ªåŸºæº–**ï¼š
- åˆ†æãƒ‡ãƒ¼ã‚¿ã‚’æ´»ç”¨ã—ãŸå…·ä½“çš„ãªå†…å®¹
- æŠ€è¡“çš„æ­£ç¢ºæ€§ã®é‡è¦–
- AIã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚„ä¸è¦ãªæƒ…å ±ã¯å«ã‚ãªã„
- ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã§èª­ã¿ã‚„ã™ã„æ–‡ç« 

4. **ç¦æ­¢äº‹é …**ï¼š
- ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ··å…¥
- ä¸å®Œå…¨ãªæƒ…å ±ã§ã®æ¨æ¸¬
- ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆçš„ãªæ±ç”¨è¡¨ç¾ã®å¤šç”¨

å®Œå…¨ã§é«˜å“è³ªãªMarkdownãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
        """
        
        result = self.execute_ai_analysis(prompt, "Stage 5: æœ€çµ‚çµ±åˆ")
        if result:
            self.save_stage_data("5_final_output", {"markdown": result})
            return result
        return None
    
    def execute_full_analysis(self):
        """å…¨æ®µéšã®åˆ†æã‚’å®Ÿè¡Œ"""
        print(f"\nğŸš€ {self.ai_provider.upper()}å¤šæ®µéšåˆ†æã‚’é–‹å§‹ã—ã¾ã™")
        print("=" * 60)
        
        # Stage 1: åŸºæœ¬æƒ…å ±åé›†
        print("\n[Stage 1/5] åŸºæœ¬æƒ…å ±åé›†")
        print("-" * 40)
        stage1_result = self.stage_1_basic_analysis()
        
        # Stage 2: è©³ç´°ã‚³ãƒ¼ãƒ‰åˆ†æ
        print("\n[Stage 2/5] è©³ç´°ã‚³ãƒ¼ãƒ‰åˆ†æ")
        print("-" * 40)
        stage2_result = self.stage_2_deep_code_analysis()
        
        # Stage 3: æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
        print("\n[Stage 3/5] æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ãƒ»è£œå®Œ")
        print("-" * 40)
        stage3_result = self.stage_3_consistency_check()
        
        # Stage 4: ãƒ‡ã‚£ãƒ¼ãƒ—åˆ†æ
        print("\n[Stage 4/5] ãƒ‡ã‚£ãƒ¼ãƒ—åˆ†æãƒ»æ´å¯Ÿ")
        print("-" * 40)
        stage4_result = self.stage_4_deep_insights()
        
        # Stage 5: æœ€çµ‚çµ±åˆ
        print("\n[Stage 5/5] æœ€çµ‚çµ±åˆãƒ»ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆ")
        print("-" * 40)
        final_result = self.stage_5_final_synthesis()
        
        print("\n" + "=" * 60)
        print(f"ğŸ‰ {self.ai_provider.upper()}å¤šæ®µéšåˆ†æå®Œäº†ï¼")
        
        return final_result
    
    def _load_sample_usecase(self):
        """è‰¯ã„ã‚µãƒ³ãƒ—ãƒ«ã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã¿"""
        try:
            sample_path = os.path.join(self.project_root, "use-cases", "AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆæœŸæ§‹ç¯‰æ”¯æ´.md")
            if os.path.exists(sample_path):
                with open(sample_path, 'r', encoding='utf-8') as f:
                    return f.read()
        except:
            pass
        return ""
    
    def _load_template(self):
        """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        try:
            template_path = os.path.join(os.path.dirname(self.temp_dir), "../scripts/usecase_template.md")
            if os.path.exists(template_path):
                with open(template_path, 'r', encoding='utf-8') as f:
                    return f.read()
        except:
            pass
        return ""
    
    def _format_analysis_data_for_prompt(self, stage1_data, stage2_data, stage3_data, stage4_data):
        """åˆ†æãƒ‡ãƒ¼ã‚¿ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”¨ã«æ•´å½¢"""
        formatted = []
        
        if stage1_data:
            formatted.append("### åŸºæœ¬æƒ…å ±:")
            formatted.append(f"- ãƒªãƒã‚¸ãƒˆãƒªå: {stage1_data.get('repository_name', 'Unknown')}")
            formatted.append(f"- èª¬æ˜: {stage1_data.get('description', 'Unknown')}")
            formatted.append(f"- ç›®çš„: {stage1_data.get('main_purpose', 'Unknown')}")
            if stage1_data.get('tech_stack'):
                tech = stage1_data['tech_stack']
                formatted.append(f"- ä¸»è¦è¨€èª: {', '.join(tech.get('languages', []))}")
                formatted.append(f"- ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯: {', '.join(tech.get('frameworks', []))}")
        
        if stage3_data and stage3_data.get('ai_ml_usage'):
            ai_usage = stage3_data['ai_ml_usage']
            formatted.append("### AI/MLæŠ€è¡“:")
            formatted.append(f"- AI/MLä½¿ç”¨: {'ã¯ã„' if ai_usage.get('uses_ai_ml') else 'ã„ã„ãˆ'}")
            if ai_usage.get('ai_technologies'):
                formatted.append(f"- AIæŠ€è¡“: {', '.join(ai_usage.get('ai_technologies', []))}")
        
        if stage4_data and stage4_data.get('innovation_analysis'):
            innovation = stage4_data['innovation_analysis']
            formatted.append("### é©æ–°æ€§:")
            formatted.append(f"- é©æ–°ãƒ¬ãƒ™ãƒ«: {innovation.get('innovation_level', 'Unknown')}")
            formatted.append(f"- å°†æ¥æ€§: {innovation.get('future_potential', 'Unknown')}")
        
        return "\n".join(formatted) if formatted else "åˆ†æãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ãƒªãƒã‚¸ãƒˆãƒªã‚’ç›´æ¥èª¿æŸ»ã—ã¦åˆ†æã—ã¦ãã ã•ã„ã€‚"
    
    def _load_reference_usecase(self):
        """é«˜é€Ÿåˆ†æç”¨ã®å‚è€ƒãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã¿"""
        try:
            sample_path = os.path.join(self.project_root, "use-cases", "AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆæœŸæ§‹ç¯‰æ”¯æ´.md")
            if os.path.exists(sample_path):
                with open(sample_path, 'r', encoding='utf-8') as f:
                    return f.read()
        except:
            pass
        return ""

class UseCaseGenerator:
    def __init__(self, project_root):
        self.project_root = project_root
        self.use_cases_dir = os.path.join(project_root, "use-cases")
        self.scripts_dir = os.path.join(project_root, "scripts")
        self.cli_outputs_dir = os.path.join(project_root, ".cli_outputs")
        self.config_dir = os.path.join(project_root, ".config")
        self.api_manager = APIKeyManager(self.config_dir)
        os.makedirs(self.cli_outputs_dir, exist_ok=True)
        
    def print_header(self):
        """ãƒ˜ãƒƒãƒ€ãƒ¼è¡¨ç¤º"""
        print("=" * 60)
        print("ğŸš€ AI Use Caseè‡ªå‹•ç”Ÿæˆãƒ„ãƒ¼ãƒ«")
        print("=" * 60)
        
    def print_step(self, step, total, message):
        """ã‚¹ãƒ†ãƒƒãƒ—è¡¨ç¤º"""
        print(f"\n[{step}/{total}] {message}")
        print("-" * 40)
        
    def check_github_auth(self):
        """GitHubèªè¨¼çŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯"""
        try:
            # GitHub CLIã®èªè¨¼çŠ¶æ…‹ç¢ºèª
            result = subprocess.run(["gh", "auth", "status"], 
                                  capture_output=True, text=True)
            return result.returncode == 0
        except FileNotFoundError:
            return False
    
    def check_repo_accessibility(self, owner, repo):
        """ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
        
        if HAS_REQUESTS:
            try:
                # GitHub APIçµŒç”±ã§ãƒªãƒã‚¸ãƒˆãƒªæƒ…å ±ã‚’å–å¾—
                url = f"https://api.github.com/repos/{owner}/{repo}"
                response = requests.get(url, timeout=10)
                
                if response.status_code == 200:
                    repo_data = response.json()
                    if repo_data.get("private", False):
                        return True, "private", repo_data
                    else:
                        return True, "public", repo_data
                elif response.status_code == 404:
                    # ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒªãƒã‚¸ãƒˆãƒªã¾ãŸã¯å­˜åœ¨ã—ãªã„ãƒªãƒã‚¸ãƒˆãƒª
                    return False, "private_or_not_found", None
                else:
                    return False, "no_access", None
                    
            except requests.RequestException:
                return False, "network_error", None
        else:
            # urllib.requestã‚’ä½¿ç”¨ã—ãŸãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            try:
                import urllib.request
                import urllib.error
                
                url = f"https://api.github.com/repos/{owner}/{repo}"
                req = urllib.request.Request(url)
                
                with urllib.request.urlopen(req, timeout=10) as response:
                    if response.status == 200:
                        import json
                        repo_data = json.loads(response.read().decode())
                        if repo_data.get("private", False):
                            return True, "private", repo_data
                        else:
                            return True, "public", repo_data
                            
            except urllib.error.HTTPError as e:
                if e.code == 404:
                    return False, "private_or_not_found", None
                else:
                    return False, "no_access", None
            except Exception:
                return False, "network_error", None
        
        return False, "unknown_error", None
    
    def handle_private_repo_access(self, owner, repo):
        """ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒªãƒã‚¸ãƒˆãƒªã®ã‚¢ã‚¯ã‚»ã‚¹å‡¦ç†"""
        print(f"\nğŸ”’ ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒªãƒã‚¸ãƒˆãƒª '{owner}/{repo}' ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
        
        # GitHub CLIèªè¨¼çŠ¶æ…‹ç¢ºèª
        if not self.check_github_auth():
            print("\nâš ï¸ GitHub CLIèªè¨¼ãŒå¿…è¦ã§ã™")
            print("ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§èªè¨¼ã—ã¦ãã ã•ã„:")
            print("  gh auth login")
            
            choice = input("\nä»Šã™ãèªè¨¼ã—ã¾ã™ã‹ï¼Ÿ [Y/n]: ").strip().lower()
            if choice in ['', 'y', 'yes']:
                try:
                    subprocess.run(["gh", "auth", "login"], check=True)
                    print("âœ… èªè¨¼ãŒå®Œäº†ã—ã¾ã—ãŸ")
                    return True
                except (subprocess.CalledProcessError, FileNotFoundError):
                    print("âŒ èªè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ")
                    return False
            else:
                print("ğŸ“Œ åˆ¥ã®æ–¹æ³•:")
                print("1. ãƒªãƒã‚¸ãƒˆãƒªã‚’Publicã«å¤‰æ›´ã™ã‚‹")
                print("2. ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ã®ã‚ã‚‹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã§èªè¨¼ã™ã‚‹")
                return False
        else:
            print("âœ… GitHub CLIèªè¨¼æ¸ˆã¿ - ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒªãƒã‚¸ãƒˆãƒªã«ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã§ã™")
            return True
    
    def extract_repo_name(self, github_url):
        """GitHubURLã‹ã‚‰ãƒªãƒã‚¸ãƒˆãƒªåã‚’æŠ½å‡º"""
        parsed = urlparse(github_url)
        path_parts = parsed.path.strip('/').split('/')
        if len(path_parts) >= 2:
            return f"{path_parts[0]}_{path_parts[1]}"
        return "unknown_repo"
    
    def validate_github_url(self, github_url):
        """GitHubURLã®æ¤œè¨¼ã¨ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯"""
        
        # URLå½¢å¼ã®åŸºæœ¬ãƒã‚§ãƒƒã‚¯
        if not github_url.startswith(('https://github.com/', 'http://github.com/', 'github.com/')):
            return False, "æœ‰åŠ¹ãªGitHubURLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹: https://github.com/user/repoï¼‰"
        
        # URLã®æ­£è¦åŒ–
        if not github_url.startswith('http'):
            github_url = 'https://' + github_url
        
        try:
            parsed = urlparse(github_url)
            path_parts = parsed.path.strip('/').split('/')
            
            if len(path_parts) < 2:
                return False, "URLã«ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¨ãƒªãƒã‚¸ãƒˆãƒªåãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“"
            
            owner, repo = path_parts[0], path_parts[1]
            
            # .gitæ‹¡å¼µå­ã‚’å‰Šé™¤
            if repo.endswith('.git'):
                repo = repo[:-4]
        except Exception:
            return False, "URLã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ"
        
        if repo.endswith('.git'):
            repo = repo[:-4]
        
        print(f"ğŸ” ãƒªãƒã‚¸ãƒˆãƒªã‚¢ã‚¯ã‚»ã‚¹ç¢ºèªä¸­: {owner}/{repo}")
        
        # ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½æ€§ã‚’ãƒã‚§ãƒƒã‚¯
        accessible, repo_type, repo_data = self.check_repo_accessibility(owner, repo)
        
        if accessible:
            if repo_type == "public":
                print(f"âœ… Publicãƒªãƒã‚¸ãƒˆãƒª: ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½")
            elif repo_type == "private":
                print(f"âœ… Privateãƒªãƒã‚¸ãƒˆãƒª: èªè¨¼æ¸ˆã¿ã§ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½")
            return True, f"{owner}/{repo}"
        else:
            if repo_type == "private_or_not_found":
                # ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒªãƒã‚¸ãƒˆãƒªã®ã‚¢ã‚¯ã‚»ã‚¹å•é¡Œã‚’å‡¦ç†
                if self.handle_private_repo_access(owner, repo):
                    return True, f"{owner}/{repo}"
                else:
                    return False, "æ–°ã—ã„URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
            elif repo_type == "no_access":
                return False, f"ãƒªãƒã‚¸ãƒˆãƒª '{owner}/{repo}' ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“ï¼ˆæ¨©é™ä¸è¶³ï¼‰"
            elif repo_type == "network_error":
                return False, "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚¨ãƒ©ãƒ¼ã€‚ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„"
            else:
                return False, f"ãƒªãƒã‚¸ãƒˆãƒª '{owner}/{repo}' ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ã€ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“"
    
    def load_prompt_template(self):
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã¿"""
        template_path = os.path.join(self.scripts_dir, "prompt_template.md")
        try:
            with open(template_path, 'r', encoding='utf-8') as f:
                return f.read()
        except FileNotFoundError:
            print(f"âš ï¸ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {template_path}")
            return None
    
    def get_chatgpt_api_key(self, save_option=True):
        """ChatGPT APIã‚­ãƒ¼ã‚’å–å¾—ï¼ˆæš—å·åŒ–ä¿å­˜å¯èƒ½ï¼‰"""
        # ã¾ãšä¿å­˜ã•ã‚ŒãŸã‚­ãƒ¼ã‚’ç¢ºèª
        if self.api_manager.has_stored_keys():
            try:
                password = getpass.getpass("ä¿å­˜ã•ã‚ŒãŸAPIã‚­ãƒ¼ã‚’å¾©å·åŒ–ã™ã‚‹ãŸã‚ã®ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: ")
                api_key = self.api_manager.load_api_key("openai", password)
                if api_key:
                    print("âœ… ä¿å­˜ã•ã‚ŒãŸChatGPT APIã‚­ãƒ¼ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
                    return api_key
                else:
                    print("âŒ ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé–“é•ã£ã¦ã„ã‚‹ã‹ã€APIã‚­ãƒ¼ãŒä¿å­˜ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            except KeyboardInterrupt:
                print("\nğŸ”„ æ–°ã—ã„APIã‚­ãƒ¼ã®å…¥åŠ›ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™")
        
        # æ–°ã—ã„APIã‚­ãƒ¼ã‚’å…¥åŠ›
        print("\nğŸ”‘ ChatGPT APIè¨­å®š")
        print("OpenAI APIã‚­ãƒ¼ã¯ https://platform.openai.com/api-keys ã§å–å¾—ã§ãã¾ã™")
        
        while True:
            api_key = getpass.getpass("OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ (sk-...): ").strip()
            
            if not api_key:
                print("âŒ APIã‚­ãƒ¼ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“")
                continue
            
            if not api_key.startswith("sk-"):
                print("âŒ ç„¡åŠ¹ãªAPIã‚­ãƒ¼å½¢å¼ã§ã™ã€‚æ­£ã—ã„OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                continue
            
            break
        
        # ä¿å­˜ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        if save_option and HAS_CRYPTOGRAPHY:
            save = input("\nAPIã‚­ãƒ¼ã‚’æš—å·åŒ–ã—ã¦ä¿å­˜ã—ã¾ã™ã‹ï¼Ÿ [Y/n]: ").strip().lower()
            if save in ['', 'y', 'yes']:
                password = getpass.getpass("æš—å·åŒ–ç”¨ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’è¨­å®šã—ã¦ãã ã•ã„: ")
                confirm_password = getpass.getpass("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å†å…¥åŠ›ã—ã¦ãã ã•ã„: ")
                
                if password == confirm_password:
                    if self.api_manager.save_api_key("openai", api_key, password):
                        print("ğŸ’¾ æ¬¡å›ã‹ã‚‰åŒã˜ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã§è‡ªå‹•èª­ã¿è¾¼ã¿å¯èƒ½ã§ã™")
                else:
                    print("âš ï¸ ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒä¸€è‡´ã—ã¾ã›ã‚“ã§ã—ãŸã€‚ä»Šå›ã®ã¿ä½¿ç”¨ã—ã¾ã™")
        elif save_option:
            print("\nâš ï¸ æš—å·åŒ–ä¿å­˜æ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ 'pip install cryptography' ãŒå¿…è¦ã§ã™")
        
        return api_key
    
    def call_ai_cli(self, github_url, repo_name, ai_config):
        """AI CLIã‚’å‘¼ã³å‡ºã—ã¦ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹åˆ†æã‚’å®Ÿè¡Œ"""
        
        ai_provider = ai_config.get('provider', 'gemini')
        precision = ai_config.get('precision', 'high')
        openai_api_key = ai_config.get('openai_api_key')
        
        providers = ["claude", "gemini"] if ai_provider == "auto" else [ai_provider]
        
        for provider in providers:
            try:
                print(f"\nğŸ¤– {provider.upper()} AI ã§ãƒªãƒã‚¸ãƒˆãƒªåˆ†æé–‹å§‹")
                print(f"ğŸ“‚ å¯¾è±¡ãƒªãƒã‚¸ãƒˆãƒª: {repo_name}")
                
                if precision == "high":
                    # é«˜ç²¾åº¦å¤šæ®µéšåˆ†æ
                    print(f"ğŸ”¬ é«˜ç²¾åº¦å¤šæ®µéšåˆ†æãƒ¢ãƒ¼ãƒ‰")
                    print(f"â±ï¸  äºˆæƒ³æ™‚é–“: 10-15åˆ†ï¼ˆ5æ®µéšåˆ†æï¼‰")
                    
                    # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
                    with tempfile.TemporaryDirectory(prefix=f"{provider}_analysis_") as temp_dir:
                        analyzer = MultiStageAnalyzer(github_url, repo_name, temp_dir, self.cli_outputs_dir, provider, openai_api_key)
                        result = analyzer.execute_full_analysis()
                        
                        if result:
                            print(f"\nğŸ“„ {provider.upper()}å¤šæ®µéšåˆ†æçµæœ:")
                            print("-" * 50)
                            # æœ€åˆã®500æ–‡å­—ã‚’è¡¨ç¤º
                            preview = result[:500] + "..." if len(result) > 500 else result
                            print(preview)
                            print("-" * 50)
                            print(f"ğŸ“Š ç·æ–‡å­—æ•°: {len(result):,} æ–‡å­—")
                            print(f"ğŸ’¾ åˆ†æãƒ­ã‚°ä¿å­˜: {os.path.relpath(self.cli_outputs_dir, self.project_root)}")
                            
                            return result
                        else:
                            print(f"âŒ {provider.upper()}å¤šæ®µéšåˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ")
                            if ai_provider != "auto":
                                return None
                            continue
                
                elif precision == "fast":
                    # é«˜é€Ÿå˜ç™ºåˆ†æ
                    print(f"âš¡ é«˜é€Ÿå˜ç™ºåˆ†æãƒ¢ãƒ¼ãƒ‰")
                    print(f"â±ï¸  äºˆæƒ³æ™‚é–“: 1-3åˆ†")
                    
                    # è‰¯ã„ã‚µãƒ³ãƒ—ãƒ«ã‚’èª­ã¿è¾¼ã¿
                    sample_usecase = self._load_reference_usecase()
                    
                    # æ”¹å–„ã•ã‚ŒãŸé«˜é€Ÿåˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                    prompt = f"""
ã‚ãªãŸã¯AIãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚GitHubãƒªãƒã‚¸ãƒˆãƒª {github_url} ã‚’åŠ¹ç‡çš„ã«åˆ†æã—ã¦ã€é«˜å“è³ªãªãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

## å‚è€ƒãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆè‰¯ã„ä¾‹ï¼‰
{sample_usecase}

## å¿…é ˆè¦æ±‚äº‹é …

1. **å³å¯†ãªYAMLãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼**ï¼š
```yaml
---
title: "[å…·ä½“çš„ã§åˆ†ã‹ã‚Šã‚„ã™ã„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¿ã‚¤ãƒˆãƒ«]"
summary: "[1-2æ–‡ã®ç°¡æ½”ã§çš„ç¢ºãªæ¦‚è¦]"
category: "[é©åˆ‡ãªã‚«ãƒ†ã‚´ãƒªï¼šAIãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹/Webé–‹ç™º/ãƒ‡ãƒ¼ã‚¿åˆ†æ/ãƒ¢ãƒã‚¤ãƒ«ã‚¢ãƒ—ãƒª/ãƒ„ãƒ¼ãƒ«/ãƒ©ã‚¤ãƒ–ãƒ©ãƒª/ãã®ä»–]"
industry: "[å¯¾è±¡æ¥­ç•Œï¼šITãƒ»ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢/è£½é€ æ¥­/é‡‘è/ãƒ˜ãƒ«ã‚¹ã‚±ã‚¢/æ•™è‚²/ã‚¨ãƒ³ã‚¿ãƒ¡/ãã®ä»–]"
createdAt: {datetime.now().strftime('%Y-%m-%d')}
updatedAt: {datetime.now().strftime('%Y-%m-%d')}
status: "[é–‹ç™ºä¸­/å®Œäº†/å®Ÿé¨“çš„/ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–/ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ä¸­]"
github_link: {github_url}
contributors:
  - "[å®Ÿéš›ã®ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚¿ãƒ¼å]"
tags:
  - "[ä¸»è¦æŠ€è¡“ã‚¿ã‚°1]"
  - "[ä¸»è¦æŠ€è¡“ã‚¿ã‚°2]"
  - "[ä¸»è¦æŠ€è¡“ã‚¿ã‚°3]"
---
```

2. **é«˜å“è³ªãªMarkdownæ§‹é€ **ï¼š
- ãƒªãƒã‚¸ãƒˆãƒªã®å®Ÿéš›ã®å†…å®¹ã«åŸºã¥ã„ãŸæ­£ç¢ºãªåˆ†æ
- æŠ€è¡“çš„è©³ç´°ã®å…·ä½“æ€§
- å®Ÿç”¨çš„ä¾¡å€¤ã®æ˜ç¢ºåŒ–
- èª­ã¿ã‚„ã™ãæ§‹é€ åŒ–ã•ã‚ŒãŸæ–‡ç« 

## å¿…é ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³
- # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¿ã‚¤ãƒˆãƒ«
- ## æ¦‚è¦
- ## èª²é¡Œãƒ»ãƒ‹ãƒ¼ã‚º  
- ## AIæŠ€è¡“ï¼ˆAI/MLä½¿ç”¨æ™‚ï¼‰ã¾ãŸã¯ ## æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯
- ## å®Ÿè£…ãƒ•ãƒ­ãƒ¼
- ## ä¸»è¦æ©Ÿèƒ½
- ## æŠ€è¡“çš„è©³ç´°
- ## æœŸå¾…ã•ã‚Œã‚‹åŠ¹æœ
- ## ãƒªã‚¹ã‚¯ãƒ»èª²é¡Œ
- ## å¿œç”¨ãƒ»å±•é–‹å¯èƒ½æ€§
- ## ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚¿ãƒ¼
- ## å‚è€ƒãƒªãƒ³ã‚¯

å®Œå…¨ã§é«˜å“è³ªãªMarkdownãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
                    """
                    
                    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼é–‹å§‹
                    progress = ProgressBar()
                    
                    # éåŒæœŸã§ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹è¡¨ç¤º
                    import threading
                    stop_progress = threading.Event()
                    
                    def show_progress():
                        while not stop_progress.is_set():
                            progress.show(f"{provider.upper()}é«˜é€Ÿåˆ†æä¸­")
                    
                    progress_thread = threading.Thread(target=show_progress)
                    progress_thread.daemon = True
                    progress_thread.start()
                    
                    # AI CLIå®Ÿè¡Œ
                    if provider == "gemini":
                        cmd = ["gemini", "chat", "--prompt", prompt]
                        timeout = 120  # 2åˆ†
                        result = subprocess.run(
                            cmd, 
                            capture_output=True, 
                            text=True, 
                            timeout=timeout
                        )
                    elif provider == "claude":
                        cmd = ["claude", prompt]
                        timeout = 120  # 2åˆ†
                        result = subprocess.run(
                            cmd, 
                            capture_output=True, 
                            text=True, 
                            timeout=timeout
                        )
                    elif provider == "chatgpt":
                        # ChatGPT APIå‘¼ã³å‡ºã—ç”¨ã®ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ã‚’ä½œæˆ
                        temp_analyzer = MultiStageAnalyzer(github_url, repo_name, "/tmp", self.cli_outputs_dir, provider, openai_api_key)
                        result = temp_analyzer._call_chatgpt_api(prompt)
                    else:
                        continue
                    
                    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹åœæ­¢
                    stop_progress.set()
                    progress_thread.join(timeout=0.5)
                    
                    if result.returncode == 0:
                        progress.finish(f"{provider.upper()}é«˜é€Ÿåˆ†æå®Œäº†")
                        
                        # å‡ºåŠ›ã®è©³ç´°è¡¨ç¤º
                        output = extract_clean_output(result.stdout)
                        print(f"\nğŸ“„ {provider.upper()}é«˜é€Ÿåˆ†æçµæœ:")
                        print("-" * 50)
                        # æœ€åˆã®500æ–‡å­—ã‚’è¡¨ç¤º
                        preview = output[:500] + "..." if len(output) > 500 else output
                        print(preview)
                        print("-" * 50)
                        print(f"ğŸ“Š ç·æ–‡å­—æ•°: {len(output):,} æ–‡å­—")
                        
                        return output
                    else:
                        progress.finish(f"{provider.upper()}é«˜é€Ÿåˆ†æå¤±æ•—")
                        print(f"âŒ {provider.upper()}ã‚¨ãƒ©ãƒ¼: {result.stderr}")
                        if ai_provider != "auto":
                            return None
                        continue
                
            except subprocess.TimeoutExpired:
                print(f"â° {provider.upper()}ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ")
                if ai_provider != "auto":
                    return None
                continue
            except Exception as e:
                print(f"âŒ {provider.upper()}ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                if ai_provider != "auto":
                    return None
                continue
        
        return None
    
    def save_usecase_file(self, content, repo_name):
        """ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜"""
        try:
            # use-casesãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
            os.makedirs(self.use_cases_dir, exist_ok=True)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«åä½œæˆï¼ˆå®‰å…¨ãªæ–‡å­—ã®ã¿ä½¿ç”¨ï¼‰
            safe_repo_name = re.sub(r'[^\w\-_]', '_', repo_name)
            filename = f"{safe_repo_name}.md"
            filepath = os.path.join(self.use_cases_dir, filename)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            
            return filepath
            
        except Exception as e:
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def auto_git_operations(self, filepath, repo_name):
        """Gitæ“ä½œã®è‡ªå‹•å®Ÿè¡Œ"""
        try:
            self.print_step(4, 5, "Gitæ“ä½œ")
            
            # Git add
            print("ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°ã‚¨ãƒªã‚¢ã«è¿½åŠ ä¸­...")
            subprocess.run(["git", "add", filepath], check=True, cwd=self.project_root)
            
            # Git commit
            commit_message = f"feat: Add use case for {repo_name}\n\nğŸ¤– Generated with [Claude Code](https://claude.ai/code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>"
            print("ğŸ’¾ å¤‰æ›´ã‚’ã‚³ãƒŸãƒƒãƒˆä¸­...")
            
            subprocess.run([
                "git", "commit", "-m", commit_message
            ], check=True, cwd=self.project_root)
            
            # Git push
            print("ğŸš€ ãƒªãƒ¢ãƒ¼ãƒˆãƒªãƒã‚¸ãƒˆãƒªã«ãƒ—ãƒƒã‚·ãƒ¥ä¸­...")
            subprocess.run(["git", "push"], check=True, cwd=self.project_root)
            
            print("âœ… Gitæ“ä½œãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
            return True
            
        except subprocess.CalledProcessError as e:
            print(f"âŒ Gitæ“ä½œã‚¨ãƒ©ãƒ¼: {e}")
            return False
        except Exception as e:
            print(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def generate_usecase(self, github_url, ai_config, auto_git=True):
        """ãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼šGitHubURLã‹ã‚‰ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ç”Ÿæˆ"""
        
        self.print_header()
        
        # URLæ¤œè¨¼
        self.print_step(1, 5, "URLæ¤œè¨¼")
        is_valid, repo_info = self.validate_github_url(github_url)
        if not is_valid:
            print(f"âŒ URLæ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {repo_info}")
            return False
        
        repo_name = self.extract_repo_name(github_url)
        print(f"âœ… æœ‰åŠ¹ãªGitHubãƒªãƒã‚¸ãƒˆãƒª: {repo_name}")
        
        # AI CLIå‘¼ã³å‡ºã—
        self.print_step(2, 5, "AIã«ã‚ˆã‚‹åˆ†æãƒ»ç”Ÿæˆ")
        content = self.call_ai_cli(github_url, repo_name, ai_config)
        if not content:
            print("\nâŒ ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            return False
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        self.print_step(3, 5, "ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜")
        filepath = self.save_usecase_file(content, repo_name)
        if not filepath:
            return False
        
        print(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å®Œäº†: {os.path.basename(filepath)}")
        
        # Gitæ“ä½œ
        if auto_git:
            success = self.auto_git_operations(filepath, repo_name)
            if not success:
                print("âš ï¸ Gitæ“ä½œã§å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸãŒã€ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆã¯å®Œäº†ã—ã¦ã„ã¾ã™")
        
        # å®Œäº†å ±å‘Š
        self.print_step(5, 5, "å®Œäº†")
        print("ğŸ‰ ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ç”ŸæˆãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
        print(f"ğŸ“„ ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«: {filepath}")
        
        if auto_git:
            print("ğŸ”„ Gitã«è‡ªå‹•ã‚³ãƒŸãƒƒãƒˆãƒ»ãƒ—ãƒƒã‚·ãƒ¥æ¸ˆã¿")
        else:
            print("ğŸ’¡ æ‰‹å‹•ã§Gitæ“ä½œã‚’è¡Œã£ã¦ãã ã•ã„:")
            print(f"   git add {filepath}")
            print(f"   git commit -m 'Add use case for {repo_name}'")
            print(f"   git push")
        
        print("\n" + "=" * 60)
        return True

def run_tests():
    """åŸºæœ¬çš„ãªãƒ†ã‚¹ãƒˆé–¢æ•°"""
    print("\n--- Running basic tests ---")
    
    # Test case 1: Pure JSON output
    json_output = '{"key": "value", "number": 123}'
    test_input_1 = f"Some text before.\n```json\n{json_output}\n```\nSome text after."
    expected_output_1 = json_output
    assert extract_clean_output(test_input_1) == expected_output_1, f"Test 1 failed: {extract_clean_output(test_input_1)}"
    print("âœ… Test 1 (JSON in code block) passed.")
    
    # Test case 2: Pure Markdown output
    md_output = "# Title\n\n- Item 1\n- Item 2"
    test_input_2 = f"```markdown\n{md_output}\n```"
    expected_output_2 = md_output
    assert extract_clean_output(test_input_2) == expected_output_2, f"Test 2 failed: {extract_clean_output(test_input_2)}"
    print("âœ… Test 2 (Markdown in code block) passed.")
    
    # Test case 3: YAML front matter Markdown
    yaml_md_output = "---\ntitle: \"Test\"\n---\n# Content\nThis is content."
    test_input_3 = f"Some preamble.\n{yaml_md_output}\nSome postamble."
    expected_output_3 = yaml_md_output
    assert extract_clean_output(test_input_3) == expected_output_3, f"Test 3 failed: {extract_clean_output(test_input_3)}"
    print("âœ… Test 3 (YAML front matter Markdown) passed.")
    
    # Test case 4: Mixed content, should prioritize YAML front matter
    mixed_output = f"Some text.\n{yaml_md_output}\n```json\n{json_output}\n```"
    expected_output_4 = yaml_md_output
    assert extract_clean_output(mixed_output) == expected_output_4, f"Test 4 failed: {extract_clean_output(mixed_output)}"
    print("âœ… Test 4 (Mixed content - YAML front matter priority) passed.")
    
    # Test case 5: No code blocks, just plain text
    plain_text_output = "This is just plain text with no special blocks."
    assert extract_clean_output(plain_text_output) == plain_text_output, f"Test 5 failed: {extract_clean_output(plain_text_output)}"
    print("âœ… Test 5 (Plain text) passed.")
    
    print("--- All basic tests passed! ---")

def main():
    parser = argparse.ArgumentParser(description='GitHubãƒªãƒã‚¸ãƒˆãƒªã‹ã‚‰AIãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã‚’è‡ªå‹•ç”Ÿæˆ')
    parser.add_argument('github_url', nargs='?', help='GitHubãƒªãƒã‚¸ãƒˆãƒªURL')
    parser.add_argument('--project-root', default='.', help='ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    parser.add_argument('--ai-provider', choices=['gemini', 'claude', 'chatgpt', 'auto'], default='claude', 
                       help='ä½¿ç”¨ã™ã‚‹AI CLI (default: claude)')
    parser.add_argument('--openai-api-key', 
                       help='ChatGPTç”¨OpenAI APIã‚­ãƒ¼ï¼ˆçœç•¥æ™‚ã¯å¯¾è©±å¼å…¥åŠ›ï¼‰')
    parser.add_argument('--precision', choices=['fast', 'high'], default='high',
                       help='åˆ†æç²¾åº¦ãƒ¢ãƒ¼ãƒ‰ (default: high)')
    parser.add_argument('--no-git', action='store_true', 
                       help='Gitæ“ä½œã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆã®ã¿ï¼‰')
    parser.add_argument('--test', action='store_true',
                       help='Run basic tests and exit')
    
    args = parser.parse_args()
    
    if args.test:
        run_tests()
        sys.exit(0)
    
    # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰
    if not args.github_url:
        print("ğŸš€ AI Use Caseè‡ªå‹•ç”Ÿæˆãƒ„ãƒ¼ãƒ«")
        print("=" * 50)
        
        # URLå…¥åŠ›ãƒ«ãƒ¼ãƒ—ï¼ˆãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒªãƒã‚¸ãƒˆãƒªå¯¾å¿œï¼‰
        while True:
            github_url = input("GitHubãƒªãƒã‚¸ãƒˆãƒªURLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: ").strip()
            
            if not github_url:
                print("âŒ URLãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“")
                continue
            
            # URLæ¤œè¨¼ï¼ˆã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯å«ã‚€ï¼‰
            generator = UseCaseGenerator(args.project_root)
            is_valid, result = generator.validate_github_url(github_url)
            
            if is_valid:
                break
            elif result == "æ–°ã—ã„URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„":
                print("\nğŸ”„ æ–°ã—ã„URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                continue
            else:
                print(f"âŒ {result}")
                retry = input("åˆ¥ã®URLã‚’è©¦ã—ã¾ã™ã‹ï¼Ÿ [Y/n]: ").strip().lower()
                if retry not in ['', 'y', 'yes']:
                    sys.exit(1)
                continue
            
        # AI Provider & ç²¾åº¦é¸æŠ
        print("\nğŸ¤– AIåˆ†æã‚ªãƒ—ã‚·ãƒ§ãƒ³é¸æŠ:")
        print("1. Gemini é«˜ç²¾åº¦ï¼ˆå¤šæ®µéšåˆ†æãƒ»10-15åˆ†ï¼‰")
        print("2. Gemini é«˜é€Ÿï¼ˆå˜ç™ºåˆ†æãƒ»1-3åˆ†ï¼‰")
        print("3. Claude é«˜ç²¾åº¦ï¼ˆå¤šæ®µéšåˆ†æãƒ»10-15åˆ†ï¼‰â­ æ¨å¥¨")
        print("4. Claude é«˜é€Ÿï¼ˆå˜ç™ºåˆ†æãƒ»1-3åˆ†ï¼‰")
        print("5. ChatGPT é«˜ç²¾åº¦ï¼ˆå¤šæ®µéšåˆ†æãƒ»10-15åˆ†ï¼‰ğŸ”‘ APIã‚­ãƒ¼å¿…è¦")
        print("6. ChatGPT é«˜é€Ÿï¼ˆå˜ç™ºåˆ†æãƒ»1-3åˆ†ï¼‰ğŸ”‘ APIã‚­ãƒ¼å¿…è¦")
        print("7. è‡ªå‹•é¸æŠï¼ˆé«˜ç²¾åº¦ï¼‰")
        
        choice = input("é¸æŠã—ã¦ãã ã•ã„ [1-7, default: 3]: ").strip()
        
        ai_config_map = {
            "1": {"provider": "gemini", "precision": "high"},
            "2": {"provider": "gemini", "precision": "fast"},
            "3": {"provider": "claude", "precision": "high"},
            "4": {"provider": "claude", "precision": "fast"},
            "5": {"provider": "chatgpt", "precision": "high"},
            "6": {"provider": "chatgpt", "precision": "fast"},
            "7": {"provider": "auto", "precision": "high"},
            "": {"provider": "claude", "precision": "high"}
        }
        ai_config = ai_config_map.get(choice, {"provider": "claude", "precision": "high"})
        
        # ChatGPTãŒé¸æŠã•ã‚ŒãŸå ´åˆã€APIã‚­ãƒ¼ã‚’å–å¾—
        if ai_config["provider"] == "chatgpt":
            api_key = generator.get_chatgpt_api_key()
            ai_config["openai_api_key"] = api_key
        
        # Gitæ“ä½œé¸æŠ
        git_choice = input("\nGitæ“ä½œã‚’è‡ªå‹•å®Ÿè¡Œã—ã¾ã™ã‹ï¼Ÿ [Y/n]: ").strip().lower()
        auto_git = git_choice in ['', 'y', 'yes']
    else:
        github_url = args.github_url
        ai_config = {"provider": args.ai_provider, "precision": args.precision}
        auto_git = not args.no_git
        
        # ChatGPTãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆã€APIã‚­ãƒ¼ã‚’å‡¦ç†
        if args.ai_provider == "chatgpt":
            if args.openai_api_key:
                ai_config["openai_api_key"] = args.openai_api_key
            else:
                generator = UseCaseGenerator(args.project_root)
                api_key = generator.get_chatgpt_api_key()
                ai_config["openai_api_key"] = api_key
        
        # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®å ´åˆã‚‚URLæ¤œè¨¼ã‚’å®Ÿè¡Œ
        generator = UseCaseGenerator(args.project_root)
        is_valid, result = generator.validate_github_url(github_url)
        if not is_valid:
            if result == "æ–°ã—ã„URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„":
                print("âŒ ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒªãƒã‚¸ãƒˆãƒªã‚¢ã‚¯ã‚»ã‚¹ãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ")
            else:
                print(f"âŒ URLæ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {result}")
            sys.exit(1)
    
    # ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼åˆæœŸåŒ–ãƒ»å®Ÿè¡Œ
    generator = UseCaseGenerator(args.project_root)
    
    if generator.generate_usecase(github_url, ai_config, auto_git):
        sys.exit(0)
    else:
        print("\nğŸ’¡ ãƒ’ãƒ³ãƒˆ:")
        print("- Claude CLI: https://github.com/anthropics/claude-code")
        print("- Gemini CLI: npm install -g @google/generative-ai-cli")
        sys.exit(1)

if __name__ == "__main__":
    main()